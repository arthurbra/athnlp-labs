{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athnlp.readers.brown_pos_corpus import BrownPosTag\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size:  17427\n",
      "train/dev/test set length:  10000 1000 1000\n",
      "First train sentence:  Merger/noun proposed/verb \n",
      "First dev sentence:  To/prt provide/verb service/noun of/adp local/adj origin/noun to/adp as/adv many/adj listeners/noun as/adp possible/adj ./. \n",
      "First test sentence:  For/adp example/noun :/. a/det sales/noun presentation/noun can/verb be/verb analyzed/verb and/conj evaluated/verb through/adp roleplaying/noun ./. \n"
     ]
    }
   ],
   "source": [
    "corpus = BrownPosTag()\n",
    "print(\"vocabulary size: \", len(corpus.dictionary.x_dict))\n",
    "print(\"train/dev/test set length: \", len(corpus.train), len(corpus.dev), len(corpus.test))\n",
    "print(\"First train sentence: \", corpus.train[0])\n",
    "print(\"First dev sentence: \", corpus.dev[0])\n",
    "print(\"First test sentence: \", corpus.test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "It/pron urged/verb that/adp the/det city/noun ``/. take/verb steps/noun to/prt remedy/verb ''/. this/det problem/noun ./. "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "[2, 1, 3, 4, 0, 5, 1, 0, 6, 1, 5, 4, 0, 5]\n"
     ]
    }
   ],
   "source": [
    "print(corpus.train[1].x)\n",
    "print(corpus.train[1].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x, num):\n",
    "    arr = np.zeros(num)\n",
    "    arr[x] = 1\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = len(corpus.dictionary.x_dict)\n",
    "label_count = len(corpus.dictionary.y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words:17427\n",
      "labels:12\n"
     ]
    }
   ],
   "source": [
    "print(\"words:\" + str(word_count))\n",
    "print(\"labels:\" + str(label_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_x(x):\n",
    "    return one_hot(x, word_count)\n",
    "\n",
    "def feature_y(y):\n",
    "    return one_hot(y, label_count)\n",
    "\n",
    "def predict(weights, x):\n",
    "    logits = np.matmul(weights, x)\n",
    "    y_hat = np.argmax(logits, axis=0)       \n",
    "    return y_hat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17427, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_test = np.random.randn(label_count, word_count)\n",
    "x_test = np.transpose(np.array([feature_x(2), feature_x(3), feature_x(5)]))\n",
    "print(np.shape(x_test))\n",
    "predict(w_test, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def accuracy_dev_vec(weights):\n",
    "    true_count = 0\n",
    "    all_count = 0\n",
    "    for i, sent in enumerate(corpus.dev[0:20]):       \n",
    "        X = []\n",
    "        Y_true = []\n",
    "        for word_idx, word in enumerate(sent.x):\n",
    "            x = feature_x(word)    \n",
    "            X.append(x)\n",
    "            y_true = sent.y[word_idx]            \n",
    "            Y_true.append(y_true)\n",
    "\n",
    "        X = np.transpose(np.array(X))\n",
    "        \n",
    "        Y_hat = predict(weights, X)\n",
    "        Y_true = np.transpose(np.array(Y_true))\n",
    "\n",
    "        if i <= 5:\n",
    "            print(\"Sent lent: \" + str(len(sent.x)))\n",
    "            print(\"weights shape: \" + str(np.shape(weights)))\n",
    "            print(\"X shape\" + str(np.shape(X)))\n",
    "            print(\"Y_true shape\" + str(np.shape(Y_true)))\n",
    "            print(\"Y_hat shape\" + str(np.shape(Y_hat)))        \n",
    "        \n",
    "        #all_count += 1\n",
    "        #if y_hat == y_true:\n",
    "        #    true_count += 1\n",
    "    #return true_count / all_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent lent: 13\n",
      "weights shape: (12, 17427)\n",
      "X shape(17427, 13)\n",
      "Y_true shape(13,)\n",
      "Y_hat shape(13,)\n",
      "Sent lent: 8\n",
      "weights shape: (12, 17427)\n",
      "X shape(17427, 8)\n",
      "Y_true shape(8,)\n",
      "Y_hat shape(8,)\n",
      "Sent lent: 2\n",
      "weights shape: (12, 17427)\n",
      "X shape(17427, 2)\n",
      "Y_true shape(2,)\n",
      "Y_hat shape(2,)\n",
      "Sent lent: 2\n",
      "weights shape: (12, 17427)\n",
      "X shape(17427, 2)\n",
      "Y_true shape(2,)\n",
      "Y_hat shape(2,)\n",
      "Sent lent: 2\n",
      "weights shape: (12, 17427)\n",
      "X shape(17427, 2)\n",
      "Y_true shape(2,)\n",
      "Y_hat shape(2,)\n",
      "Sent lent: 5\n",
      "weights shape: (12, 17427)\n",
      "X shape(17427, 5)\n",
      "Y_true shape(5,)\n",
      "Y_hat shape(5,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "w = np.random.randn(label_count, word_count)\n",
    "accuracy_dev_vec(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(accuracy_dev(w))\n",
    "\n",
    "for epoch in range(3):\n",
    "    for sent in corpus.train[0:20]:\n",
    "        for word_idx, word in enumerate(sent.x[0:20]):\n",
    "            x = feature_x(word)\n",
    "            y_hat = predict(w, x)\n",
    "            y_true = sent.y[word_idx]\n",
    "            if y_hat != y_true:\n",
    "                w[y_true] = w[y_true] + x\n",
    "                w[y_hat] = w[y_hat] - x\n",
    "    \n",
    "    print(\"Accuracy: \" + str(accuracy_dev(w)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = np.dot(w, x_0)\n",
    "print(logits)\n",
    "y_hat = np.argmax(logits)\n",
    "y_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
