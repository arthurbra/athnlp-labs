{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athnlp.readers.brown_pos_corpus import BrownPosTag\n",
    "import numpy as np\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size:  17427\n",
      "train/dev/test set length:  10000 1000 1000\n",
      "First train sentence:  Merger/noun proposed/verb \n",
      "First dev sentence:  To/prt provide/verb service/noun of/adp local/adj origin/noun to/adp as/adv many/adj listeners/noun as/adp possible/adj ./. \n",
      "First test sentence:  For/adp example/noun :/. a/det sales/noun presentation/noun can/verb be/verb analyzed/verb and/conj evaluated/verb through/adp roleplaying/noun ./. \n"
     ]
    }
   ],
   "source": [
    "corpus = BrownPosTag()\n",
    "print(\"vocabulary size: \", len(corpus.dictionary.x_dict))\n",
    "print(\"train/dev/test set length: \", len(corpus.train), len(corpus.dev), len(corpus.test))\n",
    "print(\"First train sentence: \", corpus.train[0])\n",
    "print(\"First dev sentence: \", corpus.dev[0])\n",
    "print(\"First test sentence: \", corpus.test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "It/pron urged/verb that/adp the/det city/noun ``/. take/verb steps/noun to/prt remedy/verb ''/. this/det problem/noun ./. "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "[2, 1, 3, 4, 0, 5, 1, 0, 6, 1, 5, 4, 0, 5]\n"
     ]
    }
   ],
   "source": [
    "print(corpus.train[1].x)\n",
    "print(corpus.train[1].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x, num):\n",
    "    arr = np.zeros(num)\n",
    "    arr[x] = 1\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print add padding word\n",
    "word_count = len(corpus.dictionary.x_dict) + 1\n",
    "label_count = len(corpus.dictionary.y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words:17428\n",
      "labels:12\n"
     ]
    }
   ],
   "source": [
    "print(\"words:\" + str(word_count))\n",
    "print(\"labels:\" + str(label_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_x(x):\n",
    "    return one_hot(x, word_count)\n",
    "\n",
    "def feature_gram(gram):\n",
    "    x = np.array(list(map(feature_x, gram)))\n",
    "    x = np.reshape(x, -1)\n",
    "    return x\n",
    "\n",
    "\n",
    "def feature_y(y):\n",
    "    return one_hot(y, label_count)\n",
    "\n",
    "def predict(weights, x):\n",
    "    logits = np.matmul(weights, x)\n",
    "    y_hat = np.argmax(logits, axis=0)       \n",
    "    return y_hat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "grams_num = 2\n",
    "def ngrams_sent(sent):\n",
    "    return list(ngrams(sent, grams_num, pad_left=True, pad_right=False, left_pad_symbol=word_count-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0., 0., 0., ..., 0., 0., 1.]), array([0., 1., 0., ..., 0., 0., 0.])]\n",
      "[array([0., 1., 0., ..., 0., 0., 0.]), array([0., 0., 1., ..., 0., 0., 0.])]\n",
      "[array([0., 0., 1., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.])]\n",
      "[array([0., 0., 0., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.])]\n",
      "[array([0., 0., 0., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.])]\n"
     ]
    }
   ],
   "source": [
    "for gram in ngrams_sent([1, 2, 3, 4, 5]):\n",
    "    x = map(feature_x, gram)\n",
    "    print(list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def accuracy_dev(weights):\n",
    "    true_count = 0\n",
    "    all_count = 0\n",
    "    for i, sent in enumerate(corpus.dev):       \n",
    "        #print(sent.x)\n",
    "        grams = ngrams_sent(sent.x)\n",
    "        #print(grams)\n",
    "        for word_idx, gram in enumerate(grams):   \n",
    "            x = feature_gram(gram)\n",
    "            y_true = sent.y[word_idx]            \n",
    "            y_hat = predict(weights, x)\n",
    "            \n",
    "            #print(\"weights shape: \" + str(np.shape(weights)))\n",
    "            #print(\"x shape: \" + str(np.shape(x)))\n",
    "            #print(\"y_true shape: \" + str(y_true))\n",
    "            #print(\"y_hat shape: \" + str(y_hat))\n",
    "            \n",
    "            all_count += 1\n",
    "            if y_hat == y_true:\n",
    "                true_count += 1\n",
    "    return true_count / all_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27510962622676965\n"
     ]
    }
   ],
   "source": [
    "w = np.zeros(shape=(label_count, word_count * grams_num))\n",
    "\n",
    "print(accuracy_dev(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27510962622676965\n",
      "Accuracy: 0.8821257047400293\n",
      "Accuracy: 0.8924618918354562\n",
      "Accuracy: 0.9025892670703696\n",
      "Accuracy: 0.9015452077678012\n",
      "Accuracy: 0.8993526832324076\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(accuracy_dev(w))\n",
    "\n",
    "for epoch in range(5):\n",
    "    for sent in corpus.train:\n",
    "        grams = ngrams_sent(sent.x)\n",
    "        for word_idx, gram in enumerate(grams):   \n",
    "            x = feature_gram(gram)\n",
    "            y_true = sent.y[word_idx]            \n",
    "            y_hat = predict(w, x)\n",
    "            if y_hat != y_true:\n",
    "                w[y_true] = w[y_true] + x\n",
    "                w[y_hat] = w[y_hat] - x\n",
    "    \n",
    "    print(\"Accuracy: \" + str(accuracy_dev(w)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
